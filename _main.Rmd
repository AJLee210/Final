--- 
title: "Final Project-Bookdown Portfolio"
author: "AJ Lee"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::gitbook,
  set in the _output.yml file.
new_session: yes
link-citations: yes
delete_merged_file: true
output_dir: "docs"
language:
  ui:
    chapter_name: "Chapter "
---

# About
 
This is a _portfolio_ book of the previous assignments using **Bookdown** package. 
Each **bookdown** chapter is an '.Rmd file' of the weekly assignment that I have done 
in ESS580A7 class so far. 


## How to read this book

Considering the criteria below will help you understand this book more easily.    

  1. Each chapter has its own topic and data. In other words, it is made up of a book, but it is complete in each chapter rather than sequentially.    

  2. The content of this book is to learn various techniques such as interactive graphs, map views, and regression analysis using data, and you can discover the characteristics of each chapter.    

  3. For the more convenient readability of the reader, some contents are not displayed.


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Poudre River Overview



```{r setup_1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dataRetrieval)
library(dygraphs)
library(xts)
```




The Poudre River is the main source of water for Fort Collins, flowing from the peaks of the Rocky Mountains into the western vast plains. The river travels through a variety of terrain, exhibiting ever-changing quantities that change with the seasons. **By observing the discharge of the Poudre River, I want to understand the characteristics of the river.**


## Site

![](https://i0.wp.com/coyotegulch.blog/wp-content/uploads/2011/02/cachelapoudreriver.jpg)


## Data Acquisition and Plotting tests

### Data Download

I collect water discharge data upstream and downstream of Poudre by using NWIS dataset. 

```{r downloader}

Up <- readNWISdv(siteNumbers = '06752260',
                parameterCd = '00060',
                startDate = '2017-01-01',
                endDate = '2020-01-01') %>%
  rename(Q_up = 'X_00060_00003')


Down <- readNWISdv(siteNumbers = '06752280',
                parameterCd = '00060',
                startDate = '2017-01-01',
                endDate = '2020-01-01') %>%
  rename(Q_down = 'X_00060_00003') 

River <- merge (Up, Down, by='Date')

```


### Interactive Data Plotter 

```{r, fig.cap='Discharge of the Poudre', out.width='80%', fig.asp=.75, fig.align='center'}

Up_xts <- xts(River$Q_up, order.by = River$Date)
Down_xts <- xts(River$Q_down, order.by = River$Date)
Discharge <- cbind(Up_xts, Down_xts)
dygraph(Discharge, main = "Discharge of Poudre") %>%
  dySeries("Up_xts", label = "Upstream(cfs)") %>%
  dySeries("Down_xts", label = "Downstream(cfs)") %>%
  dyLegend(show = "always", hideOnMouseOut = FALSE)



```


## Conclusions

**The Poudre River has several characteristics as below:**

- The Poudre river tends to decrease its discharge over time. This is probably seemed due to less snow, a major water resource of the Poudre.
  **Is it the impact of climate change?**
[climate change impact](https://www.colorado.edu/ecenter/energy-climate-justice/general-energy-climate-info/climate-change/impacts-colorado)

- *The Flow tends to decrease as going downstream. This is believed to be due to either a runoff of water for cultivating nearby agricultural land or a sharply reduced flow rate as it approaches the plains.*

- Do you know that the main fish that inhabits in the Poudre is Brown trout that is non-native fish?
 [Poudre fishing report](https://troutunderground.com/Cache-La-Poudre-River-Fishing-Report/)
  
- Finally, I think one of the most fun things to do in Poudre is rafting along the rough rivers in summer. If you do not yet, try it this summer. **Have some cool fun in Poudre**
![](https://www.awanderlustadventure.com/wordpress/wp-content/uploads/2015/01/DSC0253.jpg)

<!--chapter:end:01-rmarkdown_examples.Rmd-->

---
title: "Hayman Fire Recovery"
author: "AJ Lee"
date: "Feb/3/2022"
output: html_document


---

```{r setup_2, warning=F,message=F}
library(tidyverse)
library(tidyr)
library(ggthemes)
library(lubridate)

# Now that we have learned how to munge (manipulate) data
# and plot it, we will work on using these skills in new ways

knitr::opts_knit$set(root.dir='.')

```

# Hayman Fire Recovery

```{r dataread, warning=F,message=F}
####-----Reading in Data and Stacking it ----- ####
#Reading in files
files <- list.files('./data',full.names=T)


#Read in individual data files
ndmi <- read.csv(files[1]) %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndmi')


ndsi <- read.csv(files[2]) %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndsi')

ndvi <- read.csv(files[3])%>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndvi')

# Stack as a tidy dataset
full_long <- rbind(ndvi,ndmi,ndsi) %>%
  gather(key='site',value='value',-DateTime,-data) %>%
  filter(!is.na(value))


```


## Question 1 

1) What is the correlation between NDVI and NDMI? - here I want you to
convert the full_long dataset in to a wide dataset using the 
function "spread" and then make a plot that shows the correlation as a
function of if the site was burned or not (x axis should be ndmi)
You should exclude winter months and focus on summer months.  
**A: NDVI and NDMI are positively correlated. This is easy to understand given that moisture is an important element of vegetation. In particular, the unburned area showed a clearer relationship within the narrow vegetation range than the burned area. The burned area shows a broad plot due to the fire, but still appears to be closely related to moisture.**

```{r, warning=F,message=F, fig.cap='Correlation between NDVI and NDMI', out.width='80%', fig.asp=.75, fig.align='center'}

full_wide <- spread(data=full_long, key='data', value='value') %>%
  filter_if(is.numeric, all_vars(!is.na(.))) %>%
  mutate(month = month(DateTime),
         year = year(DateTime))

summer_only <- filter(full_wide, month %in% c(6,7,8,9))

ggplot(summer_only,aes(x=ndmi, y=ndvi, color=site)) + 
  geom_point() + 
  theme_few() + 
  scale_color_few() + 
  theme(legend.position=c(0.8,0.8))

```



## Question 2 

2) What is the correlation between average NDSI (normalized
 snow index) for January - April and average NDVI for June-August?
In other words, does the previous year's snow cover influence vegetation
 growth for the following summer?  
 **A: NDVI and NDSI do not appear to show a significant correlation in this study. As shown in the graph, snow cover does not seem to have a significant effect on vegetation growth because ndvi maintains a constant value regardless of increase in ndsi. However, a different pattern can be seen for burned areas. Although it is not certain, it is judged that snow is helpful for the growth of plants in burnt areas remained devastated, because it shows a slight positive correlation between ndsi and ndvi.**
```{r, warning=F, message=F, fig.cap='Correlation between average NDSI, NDVI', fig.align='center'}

NDSI_NDVI <- mutate(full_long, month=month(DateTime), 
                    year=year(DateTime)) %>%
            filter((data=='ndsi' & month %in% c(1:4))|(data=='ndvi' & month %in% c(6,7,8))) %>% 
            group_by(data,site,year) %>% 
            summarize(mean_value=mean(value)) %>% 
            spread(key='data', value='mean_value')

 ggplot(NDSI_NDVI, aes(x=ndsi, y=ndvi, color=year)) +
  geom_point() +
  theme_few() +
  theme(legend.position=c(0.8,0.2)) +
  facet_wrap(~site)


```


## Question 3

3) How is the snow effect from question 2 different between pre- and post-burn
   and burned and unburned?  
   **A: As can be seen in the graph above, the vegetation index decreased sharply after the fire, but considering that the correlation between NDSI and NDVI in the wildfire area showed a slight positive correlation in the wide range, the snow impact for growth of plant appears to be greater than before. In un-burned areas, plant growth seems to be constant regardless of the amount of snow. And if you look at the color of the plots, you can see that it is trending less snow these days than it was in the past.**



## Question 4

4) What month is the greenest month on average? Does this change in the burned 
   plots after the fire?  
**A: Before the wildfire, September was the greenest month on average, and after 
   the fire, August was the greenest month in burned area. The cause of the 
   difference is unclear, but it is speculated that the greenest month has changed
   as forest fires have removed trees that could have remained green until September.**

```{r, warning=F,message=F, fig.cap='The greenest month on average after fire', fig.align='center'}

Green_ndvi <- gather(ndvi, key='site',value='NDVI',-DateTime,-data) %>%
              filter(!is.na(NDVI)) %>% 
              mutate(month = month(DateTime)) %>%
              group_by(site, month) %>% 
              summarize(mean_NDVI=mean(NDVI)) 


ggplot(Green_ndvi, aes(x=month, y=mean_NDVI, color=site)) +
  geom_point() +
  geom_line(linetype=2) +
  theme_few() +
  scale_color_few() +
  theme(legend.position=c(0.5,0.2)) +
  annotate("rect", xmin=8, xmax = 9, ymin = 0.1, ymax=0.46, alpha=.1, fill='blue')

```



## Question 5

5) What month is the snowiest on average?  
**A: Before the wildfire, February was the snowiest month on average, and after 
  the fire, January was ranked the snowiest month on average in burned area.
  The cause of this difference is also unclear as in Question 4, but it is 
  presumed that the density of vegetation influenced the amount of snow cover.**
```{r, warning=F,message=F, fig.cap='The snowiest month on average after fire', fig.align='center'}

Snow_ndsi <- gather(ndsi, key='site', value='NDSI', -DateTime, -data) %>% 
             filter(!is.na(NDSI)) %>% 
             mutate(month = month(DateTime)) %>% 
             group_by(site, month) %>% 
             summarize(mean_NDSI=mean(NDSI))

ggplot(Snow_ndsi, aes(x=month, y=mean_NDSI, color=site)) +
  geom_point() +
  geom_line(linetype=2) +
  theme_few() +
  scale_color_few() +
  theme(legend.position=c(0.5,0.8))

```


## Bonus Question: Redo all problems with `spread` and `gather` using modern tidyverse syntax. 


## Bonus Question: Use Climage Engine to pull the same data for the assignment, but updated with 2020/2021 data.





<!--chapter:end:02-fire_data_wrangle.Rmd-->

---
title: "Snow Data Assignment: Web Scraping, Functions, and Iteration"
author: "AJ Leer"
date: "2-8-2022"
output: html_document
---

```{r setup_3, include=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(readxl)

```

# Snow function iteration

## Simple web scraping

R can read html using either rvest, xml, or xml2 packages. Here we are going to navigate to the Center for Snow and Avalance Studies  [Website](https://snowstudies.org/archived-data/) and read a table in. This table contains links to data we want to programatically download for three sites. We don't know much about these sites, but they contain incredibly rich snow, temperature, and precip data. 


## Q1. Reading an html 

### Extract txt links from webpage

```{r}
site_url <- 'https://snowstudies.org/archived-data/'

#Read the web url
webpage <- read_html(site_url)

#See if we can extract tables and get the data that way
tables <- webpage %>%
  html_nodes('table') %>%
  magrittr::extract2(3) %>%
  html_table(fill = TRUE)

#That didn't work, so let's try a different approach

#Extract only weblinks and then the URLs!
links <- webpage %>%
  html_nodes('a') %>%
  .[grepl('forcing',.)] %>%
  html_attr('href')

```

## Q2. Data Download

### Download data in a for loop

```{r}

#Grab only the name of the file by splitting out on forward slashes
splits <- str_split_fixed(links,'/',8)

#Keep only the 7th column
dataset <- splits[,8] 

#generate a file list for where the data goes
file_names <- paste0('data/', dataset)

for(i in 1:2){
  download.file(links[i],destfile=file_names[i])
}

downloaded <- file.exists(file_names)

evaluate <- !all(downloaded)

```


### Download data in a map

```{r}

#Map version of the same for loop (downloading 3 files)
if(evaluate == T){
  map2(links[1:2],file_names[1:2],download.file)
}else{print('data already downloaded')}

```

## Q3. Read pdf to make a new column header appending a site column

```{r, message=F}

#Grabs the variable names from the metadata pdf file
library(pdftools)
headers <- pdf_text('https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf') %>%
  readr::read_lines(.) %>%
  trimws(.) %>%
  str_split_fixed(.,'\\.',2) %>%
  .[,2] %>%
  .[1:26] %>%
  str_trim(side = "left") %>% 
  append("site")

```


## Q4. Read the forcing data using map function and summary

```{r}
#Read the data as a map function 
our_forcing_reader <- function(file){
  name = str_split_fixed(file,'/',2)[,2] %>%
    gsub('_Forcing_Data.txt','',.) %>% 
    gsub('SBB_','',.) 
    df <- read.delim(file, header = F, sep = "", col.names = headers) %>%
    select(year, month, air.temp..K., site) %>%
    mutate(site = name)
}

forcing_data_full <- map_dfr(file_names, our_forcing_reader) 

summary(forcing_data_full)

```


## Q5. Plot mean temperature data
**A: The mean temperature in SASP is always warmer than the one of SBSP.** 
```{r, message=F, fig.cap='The mean temperature', fig.align='center'}
#make annually mean temperature data frame
temp_yearly <- forcing_data_full %>%
  group_by(year, site) %>%
  summarize(mean_temp = mean(air.temp..K.,na.rm=T))

#plot graph
ggplot(temp_yearly,aes(x=year,y=mean_temp,color=site)) + 
  geom_point() +
  geom_line() +
  labs(x='Year', y='Mean temperature (Kelvin)') +
  ggthemes::theme_few() + 
  ggthemes::scale_color_few() +
  theme(legend.position=c(0.8,0.3))

```


## Q6. Plot monthly average temperature
**A: As can be seen graphs below, the monthly average temperature at the SASP(Snow Angel Study Plot) is always higher than the one of SBSP(Senator Beck Study Plot) in any given years from 2005 to 2010. So, we can't say that SBSP is warmer than SASP**

```{r, message=F, fig.cap='Monthly average temperature by year', fig.show='hold', fig.align='center', out.width='50%'}
#make monthly temperature data frame
temp_monthly <- forcing_data_full %>% 
  group_by(year, month, site) %>% 
  summarize(average_temp = mean(air.temp..K.,na.rm=T))

#plot the graph by given year(2005~2010)
for(i in 2005:2010){
  temp_monthly_by_year <- filter(temp_monthly, year==i)
  plot(ggplot(temp_monthly_by_year, aes(x=month, y=average_temp, color = site)) + 
   geom_point() +
   geom_line() +
   ggthemes::theme_few() + 
   ggthemes::scale_color_few() +
   theme(legend.position=c(0.1,0.8)) +
   labs(title=i, y="Monthly Mean Temperature (K)", x="Month"))
}
 
```



## Bonus1, Daily precipitation by year
```{r, message=F, fig.cap="Daily precipitation by year", fig.align='center'}
#Read the data as a map function & append a site column to the data

our_precip_reader <- function(file){
  name = str_split_fixed(file,'/',2)[,2] %>%
    gsub('_Forcing_Data.txt','',.) %>% 
    gsub('SBB_','',.)
    df <- read.delim(file, header = F, sep = "", col.names = headers) %>%
    select(year, month, day, precip..kg.m.2.s.1.) %>%
    mutate(site = name)
}

precip_data_full <- map_dfr(file_names, our_precip_reader) 


#average daily precipitation by year

precip_yearly <- precip_data_full %>%
  group_by(year, month, day, site) %>%
  summarize(daily_precip = mean(precip..kg.m.2.s.1.,na.rm=T)*24*3600)

ggplot(precip_yearly,aes(x=year,y=daily_precip, color=site)) + 
  geom_point() +
  geom_line() +
  labs(x="Year", y="Daily Precipitation (mm)") +
  ggthemes::theme_few() + 
  ggthemes::scale_color_few() +
  theme(legend.position=c(0.8,0.8))

```

## Bonus2, yearly plots of percipitation by day of year
```{r, message=F, fig.cap="Yearly plots of Daily precipitation by year", fig.align='center'}
precip_daily <- precip_data_full %>% 
  group_by(year, month, site) %>% 
  summarize(average_day_precip = mean(precip..kg.m.2.s.1.,na.rm=T)*24*3600)

#plot the graph by given year(2005~2010)
par(mfrow=c(2,3))

for(i in 2005:2010){
  precip_daily_by_year <- filter(precip_daily, year==i)   
  plot(x=precip_daily_by_year$month, y=precip_daily_by_year$average_day_precip,
       xlab="month", ylab="average daily precipitation (mm)", main = i,
       type="b")
}


```


<!--chapter:end:03-snow_function_iteration.Rmd-->

---
title: "LAGOS Spatial Analysis"
author: "AJ Lee"
date: "2/21/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r setup_4, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(ggthemes)
```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)

```{r data-read, warning=F}

# #Lagos download script
LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path())


#Load in lagos
lagos <- lagosne_load()

#Grab the lake centroid info
lake_centers <- lagos$locus

```



### Convert to spatial data
```{r}

#Look at the column names
#names(lake_centers)

#Look at the structure
#str(lake_centers)

#View the full dataset
#View(lake_centers %>% slice(1:100))

spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326) %>%
  st_transform(2163)

#Subset for plotting
subset_spatial <- spatial_lakes %>%
  slice(1:100) 

subset_baser <- spatial_lakes[1:100,]

#Dynamic mapviewer
#mapview(subset_spatial)

```


### Subset to only Minnesota

```{r}

states <- us_states()

#Plot all the states to check if they loaded
#mapview(states)

minnesota <- states %>%
  filter(name == 'Minnesota') %>%
  st_transform(2163)

#Subset lakes based on spatial position
minnesota_lakes <- spatial_lakes[minnesota,]

#Plotting the first 1000 lakes
minnesota_lakes %>%
  arrange(-lake_area_ha) %>%
    slice(1:1000) %>%
  mapview(.,zcol = 'lake_area_ha')

```



## In-Class work


### 1) Show a map outline of Iowa and Illinois (similar to Minnesota map upstream)

```{r}

Iowa_Illinois <- states %>% 
              filter(name %in% c('Iowa', 'Illinois')) %>% 
              st_transform(2163)

mapview(Iowa_Illinois)

```



### 2) Subset LAGOS data to these sites, how many sites are in Illinois and Iowa
combined? How does this compare to Minnesota?  
**A: Iowa and Illinois have 16,466 sites, fewer than Minnesota, which has 29,038.**
```{r}

Iowa_Illinois_lakes <- spatial_lakes[Iowa_Illinois,]
nrow(Iowa_Illinois_lakes)
nrow(minnesota_lakes)

```


### 3) What is the distribution of lake size in Iowa vs. Minnesota?

- Here I want to see a histogram plot with lake size on x-axis and frequency on 
y axis (check out geom_histogram)

**A: As can be seen in the histogram below, both Iowa and Minnesota show a larger distribution of numbers with smaller lakes. However, since the number of lakes in Minnesota is much higher than in Iowa, it can be seen that the distribution of lakes is more diverse and wider.**

```{r, warning=F, fig.cap="Compare lake size between Iowa and Minnesota", fig.align='center'}

# Make Iowa's lake size data not Iowa_Illinois, using lake area
Iowa <- states %>% 
        filter(name=='Iowa') %>% 
        st_transform(2163)

Iowa_lakes <- spatial_lakes[Iowa,]

Iowa_lakes_size <- data.frame(Iowa_lakes$lake_area_ha) %>% 
                   rename(Lake_Size=1) %>% 
                   mutate(State='Iowa')

  
# Make Minnesota's lakes size data in similar way
minnesota_lakes_size <- data.frame(minnesota_lakes$lake_area_ha) %>%
                        rename(Lake_Size=1) %>% 
                        mutate(State='Minnesota')


# Bind two data frames to make a plot
Compare_lake_size <- rbind(Iowa_lakes_size, minnesota_lakes_size)


# Make a histogram plot
p<- ggplot(Compare_lake_size, aes(x=Lake_Size, fill=State)) +
       xlim(1,200) +
       xlab('Lake Size(ha)') +
       geom_histogram(bins = 100, alpha=0.5) +
       theme_few() + 
       theme(legend.position=c(0.8,0.7))

p+scale_fill_manual(values = c("Red", "Green")) 


```


### 4) Make an interactive plot of lakes in Iowa and Illinois and color them by lake area in hectares

```{r}
Iowa_Illinois_lakes %>%
  arrange(-lake_area_ha) %>%
  slice(1:1000) %>%
  mapview(.,zcol = 'lake_area_ha')


```


### 5) What other data sources might we use to understand how reservoirs and natural lakes vary in size in these three states?  
**A: For comparing lake size in another way, you can use perimeter length of lakes instead of lake area. The map below shows the variation of lake size using perimeter of lakes in three states. **
```{r}
Compare_lake_length <- rbind(minnesota_lakes, Iowa_Illinois_lakes)

Compare_lake_length %>% 
  arrange(-lake_perim_meters) %>% 
  slice(1:1000) %>% 
  mapview(., zcol='lake_perim_meters')

```




<!--chapter:end:04-beginning_spatial_analysis.Rmd-->

---
title: "Lake Water Quality Analysis"
author: "AJ LEE"
date: "2/21/2022"
output: html_document
---



```{r setup_5, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
```


# LAGOS Analysis 2


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read_2, warning=F}
#Lagos download script
# lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T)

#Load in lagos
lagos <- lagosne_load()


#Grab the lake centroid info
lake_centers <- lagos$locus

# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326) %>% 
                          st_transform(2163)

#Grab the water quality data
nutr <- lagos$epi_nutr

#Look at column names
#names(nutr)

```

### Subset columns nutr to only keep key info that we want


```{r}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))

```


### Keep sites with at least 200 observations 

```{r}

#Look at the number of rows of dataset
#nrow(clarity_only)

chla_secchi <- clarity_only %>%
  filter(!is.na(chla),
         !is.na(secchi))

# How many observatiosn did we lose?
# nrow(clarity_only) - nrow(chla_secchi)


# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200)

```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                          distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')

# mapview(spatial_200)

```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake

mean_values_200 <- chla_secchi_200 %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))

#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid')  
                 
#Make a map
mapview(mean_spatial,zcol='log10_mean_chl')


```


## Class work

### 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for sites with at least 200 observations?

- Here, I just want a plot of chl vs secchi for all sites  

<span style="color:blue"> 
**A: The plot below shows that high chlorophyll(chla) shorten the depth of secchi disk, which means a negative correlation.** </span>

```{r}
#Your code here
plot(mean_chl ~ mean_secchi, data=mean_spatial,  
  xlab="Mean secchi (m)" ,  
  ylab="Mean Chlorophyll (mg/L)")

```


### Why might this be the case? 
<span style="color:blue">
**A: The increase in chlorophyll in the water means high turbidity, and it is difficult to see the secchi disk to the depths because it interferes with visibility in the water. ** </span>


### 2) What states have the most data? 

#### 2a) First you will need to make a lagos spatial dataset that has the total number of counts per site.

```{r}
#head(chla_secchi)

chla_secchi_most <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>% 
  summarize(Total_by_lake = sum(count))

spatial_most <- inner_join(spatial_lakes,chla_secchi_most,
                          by='lagoslakeid')

```


#### 2b) Second, you will need to join this point dataset to the us_boundaries data. 

```{r}
states <- us_states() %>% 
          st_transform(2163)

US_spatial_most <- st_join(spatial_most, states)

# mapview(US_spatial_most)

```


#### 2c) Then you will want to group by state and sum all the observations in that state and arrange that data from most to least total observations per state. 

<span style="color:blue"> 
**A: The state has the most data about lake is Minnesota, which observation number is about over 6 million in chlorophyll and secchi data record.** </span>

```{r}
US_lake_Observation <- US_spatial_most %>% 
                       group_by(name) %>% 
                       summarize(Observation=sum(Total_by_lake)) %>% 
                       arrange(-Observation)

# head(US_lake_Observation)
mapview(US_lake_Observation, zcol='Observation')

```


#### Bonus: Map of total observation number by state not lake sites

```{r}
spatial_most_state <- inner_join(spatial_most, lagos$state, by='state_zoneid') %>% 
                      select('state_name', 'Total_by_lake') %>% 
                      group_by(state_name) %>% 
                      summarize(Observation=sum(Total_by_lake))

spatial_most_state$geometry <- NULL


US_lake_Observation_option <- inner_join(states, spatial_most_state, by='state_name')

mapview(US_lake_Observation_option, zcol='Observation')


```




### 3) Is there a spatial pattern in Secchi disk depth for lakes with at least 200 observations?  

<span style="color:blue">
**A: It can be seen that the high secchi depth value, which means the clarity of water, is mainly distributed in the northeastern regions such as Minnesota, Michigan, New York, and Maine.**</span> 
```{r}

# Extract the secchi data from original nutrition data
Secchi <- nutr %>% 
          select(lagoslakeid, sampledate, secchi) %>% 
          mutate(sampledate = as.character(sampledate) %>% ymd(.))

# Filter only the data above 200 observation
Secchi_200 <- Secchi %>% 
              group_by(lagoslakeid) %>% 
              mutate(count=n()) %>% 
              filter(count > 200)

# Join the data to spatial platform
Secchi_200_spatial <- inner_join(spatial_lakes, Secchi_200, by='lagoslakeid') %>% 
                      arrange(-secchi) %>% 
                      slice(1:30000)

# Check a spatial pattern using mapview 
mapview(Secchi_200_spatial, zcol='secchi')

```



<!--chapter:end:05-lake_wq_analysis.Rmd-->

---
title: "Weather and Corn Yield Regressions"
author: "AJ Lee"
date: "3/1/2022"
output: html_document

---

```{r setup_6, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(R.matlab)
library(rnassqs)
```

# Weather Data Analysis

## Load the PRISM daily maximum temperatures

```{r tmax data, warning=F, echo=F}

# daily max temperature
# dimensions: counties x days x years
prism <- readMat("data/prismiowa.mat")

# look at county #1
t_1981_c1 <- prism$tmaxdaily.iowa[1,,1]
#t_1981_c1[366] 
plot(1:366, t_1981_c1, type = "l")

ggplot() +
  geom_line(mapping = aes(x=1:366, y = t_1981_c1)) +
  theme_bw() +
  xlab("day of year") +
  ylab("daily maximum temperature (°C)") +
  ggtitle("Daily Maximum Temperature, Iowa County #1")


```
```{r tidying up, echo=F}

# assign dimension names to tmax matrix
dimnames(prism$tmaxdaily.iowa) <- list(prism$COUNTYFP, 1:366, prism$years)

# converted 3d matrix into a data frame
tmaxdf <- as.data.frame.table(prism$tmaxdaily.iowa)

# relabel the columns
colnames(tmaxdf) <- c("countyfp","day","year","tmax")
tmaxdf <- tibble(tmaxdf)

```

## Temperature trends

### Summer temperature trends: Winneshiek County

```{r temp trends, echo=F, message=FALSE}

tmaxdf$day <- as.numeric(tmaxdf$day)
tmaxdf$year <- as.numeric(as.character(tmaxdf$year))

winnesummer <- tmaxdf %>%
  filter(countyfp==191 & day >= 152 & day <= 243) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnesummer, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_summertmax <- lm(meantmax ~ year, winnesummer)
#summary(lm_summertmax)

```

### Winter Temperatures - Winneshiek County

```{r winter temps, echo=F, message=FALSE}

winnewinter <- tmaxdf %>%
  filter(countyfp==191 & (day <= 59 | day >= 335) & !is.na(tmax)) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnewinter, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_wintertmax <- lm(meantmax ~ year, winnewinter)
#summary(lm_wintertmax)

```

### Multiple regression -- Quadratic time trend

```{r quadratic temp trend, echo=F}

winnewinter$yearsq <- winnewinter$year^2

lm_wintertmaxquad <- lm(meantmax ~ year + yearsq, winnewinter)
#summary(lm_wintertmaxquad)
winnewinter$fitted <- lm_wintertmaxquad$fitted.values

ggplot(winnewinter) +
  geom_point(mapping = aes(x = year, y = meantmax)) +
  geom_line(mapping = aes(x = year, y = fitted)) +
  theme_bw() +
  labs(x = "year", y = "tmax")

```

### Download NASS corn yield data

```{r yield download, include=F}

# set our API key with NASS
nassqs_auth(key = "D1B740E5-CCCB-3170-B6CD-486B03AC6CC3")

# parameters to query on 
params <- list(commodity_desc = "CORN", util_practice_desc = "GRAIN", prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

# download
cornyieldsall <- nassqs_yields(params)

cornyieldsall$county_ansi <- as.numeric(cornyieldsall$county_ansi)
cornyieldsall$yield <- as.numeric(cornyieldsall$Value)

# clean and filter this dataset
cornyields <- select(cornyieldsall, county_ansi, county_name, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
cornyields <- tibble(cornyields)

```

<span style="color:blue">
## Assignment
</span>

### Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend?  
<span style="color:blue">
**A: As seen the graph below, we can say the trend of corn yield in Winneshiek County has been increasing over time.**</span>  

```{r, message=FALSE}

winncorn <- cornyields %>% 
   filter(county_ansi == 191)

ggplot(winncorn, mapping = aes(x= year, y= yield)) +
  geom_point() +
  theme_bw() +
  labs(x='Year', y='Corn yield [bu/ac]') +
  geom_smooth(method = lm , color='red')

```


### Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? 
<span style="color:blue">
**A: The plot line (blue) with quadratic time trend applied is seemed to have no evidence for slowing yield growth. Instead it shows a similar trend to the previous actual yield graph because the regression plot line is same with reference line(red). **</span>

```{r, message=FALSE}
winncorn$yearsq <- (winncorn$year)^2

lm_winncornquad <- lm(yield ~ year + yearsq, winncorn)
summary(lm_winncornquad)

winncorn$fitted <- lm_winncornquad$fitted.values

ggplot(winncorn, mapping = aes(x = fitted, y = yield)) +
  geom_point() +
  geom_smooth(method=lm) +
  geom_abline(intercept = 0, slope = 1, color='red', lty='dashed') +
  theme_bw() +
  labs(x = "Fitted Yield", y = "Actual Yield")


```


### Question 2 -- Time Series: Let's analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results.
<span style="color:blue">
**A: The relationship between temperature and yield in the winneshiek time series shows a generally negative trend as shown in the figures below. In particular, linear regression models with "Tmax squared" as a predictor give a very distinct quadratic equation result. So we will be able to predict accurate corn yields using this model.** </span>

```{r, message=FALSE}

winncorn_tmax <- inner_join(winncorn, winnesummer, by= 'year') %>% 
                 select(county_name, year, yield, meantmax)
# str(winncorn_tmax)

#1) Corn yield ~ Tmax
lm_winncorn_tmax <- lm(yield ~ meantmax, winncorn_tmax)
summary(lm_winncorn_tmax)

ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=yield, color=year)) +
  geom_point() + 
  theme_bw() +
  labs(x='Tmax (°C)', y='Corn yield [bu/ac]') +
  ggtitle("Relation between Corn yield and Summer Temperature") +
  geom_smooth(method=lm)


#2) Add year prediction variable
lm_winncorn_tmax_year <- lm(yield ~ meantmax + year, winncorn_tmax)
summary(lm_winncorn_tmax_year)
winncorn_tmax$fitted_year <- lm_winncorn_tmax_year$fitted.values

ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=fitted_year, color=year)) +
  geom_point() + 
  theme_bw() +
  labs(x='Tmax (°C)', y='Corn yield [bu/ac]') +
  ggtitle("Relation between Corn yield and Summer Temperature") +
  geom_smooth(method=lm)


#3) OR Add Tmax squared prediction variable
winncorn_tmax$tmaxsq <- (winncorn_tmax$meantmax)^2
lm_winncorn_tmaxsq <- lm(yield ~ meantmax + tmaxsq, winncorn_tmax)
summary(lm_winncorn_tmaxsq)
winncorn_tmax$fitted_tmaxsq <- lm_winncorn_tmaxsq$fitted.values

ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=fitted_tmaxsq, color=year)) +
  geom_point() + 
  theme_bw() +
  labs(x='Tmax (°C)', y='Corn yield [bu/ac]') +
  ggtitle("Relation between Corn yield and Summer Temperature") +
  geom_smooth(method=loess)


```


### Question 3 -- Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results.
<span style="color:blue">
**A: Based on the result of regression analysis, the p-value is less than alpha(=0.05), so we can determine that there is a relationship between temperature and yield, and the relationship is positive trend as you can see the below figure.** </span>

```{r, message=FALSE}

#Extract temperature data across all counties in 1981
tmaxdf_1981 <- tmaxdf %>% 
  filter(year==1981 & day >= 152 & day <=243 & !is.na(tmax)) %>% 
  group_by(countyfp) %>% 
  summarise(meantmax = mean(tmax))
tmaxdf_1981$countyfp <- as.numeric(tmaxdf_1981$countyfp)

#Extract yield data across all counties in 1981, and Change column name to join two dataset
cornyields_1981 <- cornyields %>% 
  filter(year==1981, !is.na(yield))
colnames(cornyields_1981)[1] <- "countyfp"

#Join two dataset  
Tmax_yield_all <- inner_join(tmaxdf_1981, cornyields_1981, by="countyfp")

ggplot(Tmax_yield_all, mapping = aes(x=meantmax, y=yield)) +
  geom_point() +
  theme_bw() +
  labs(x='Tmax (°C)', y='Corn yield [bu/ac]', title='Relation between temperature and yield in 2018')+
  geom_smooth(method=lm)

#Analyze regression
LMFit <- lm(yield ~ meantmax, data=Tmax_yield_all)
summary(LMFit)

```

### Question 4 -- Panel: One way to leverage multiple time series is to group all data into what is called a "panel" regression. Convert the county ID code ("countyfp" or "county_ansi") into factor using as.factor, then include this variable in a regression using all counties' yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model.
<span style="color:blue">
**A: The result of comparing actual and fitted yields is almost same to reference line(red, y=x). So to say, we would probably able to infer predicted corn yield close to actual yields through this panel regression model. And there is no significant difference in the result due to temperature coefficients change(Tmax, Tmaxsq).** </span>

```{r, message=FALSE}
#Extract temperature data across all counties 
tmaxdf_years <- tmaxdf %>% 
  filter(day >= 152 & day <=243 & !is.na(tmax)) %>% 
  group_by(countyfp) %>% 
  summarise(meantmax = mean(tmax))


#Extract yield data across all counties, and Change column name to join two dataset
cornyields_years <- cornyields %>% 
  filter(!is.na(yield))

colnames(cornyields_years)[1] <- "countyfp"
cornyields_years$countyfp <- as.factor(cornyields_years$countyfp)

#Join two dataset  
Tmax_yield_all_years <- inner_join(tmaxdf_years, cornyields_years, by="countyfp")

#Regression analysis and plot -Tmax
LMFit2 <- lm(yield ~ meantmax + countyfp, data=Tmax_yield_all_years)
#summary(LMFit2)

Tmax_yield_all_years$fitted <- LMFit2$fitted.values

ggplot(Tmax_yield_all_years, mapping = aes(x=fitted, y=yield)) +
  geom_point() +
  geom_smooth (method = lm) +
  geom_abline(intercept = 0, slope = 1, color='red', lty='dashed') +
  theme_bw() +
  labs(x='Fitted Yield', y='Actual Yield',
       title='Compareing Actual and Fitted Yields in panel regression (Tmax)')

#Regression analysis and plot -Tmax squared
Tmax_yield_all_years$tmaxsq <- (Tmax_yield_all_years$meantmax)^2
LMFit3 <- lm(yield ~ meantmax + tmaxsq + countyfp , data=Tmax_yield_all_years)
#summary(LMFit3)
Tmax_yield_all_years$fitted2 <- LMFit3$fitted.values

ggplot(Tmax_yield_all_years, mapping = aes(x=fitted2, y=yield)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline (intercept = 0, slope = 1, col='red', lty='dashed') +
  theme_bw() +
  labs(x='Fitted Yield', y='Actual Yield',
       title='Compareing Actual and Fitted Yields in panel regression (Tmax+Tmaxsq)')

```


### Question 5 -- Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years.  
<span style="color:blue">
**A: We can find the correlation under various conditions through the below figures.** </span>

```{r, results='hide'}

#Parameters to query on for soybean data
params2 <- list(commodity_desc = "SOYBEANs", statisticcat_desc="YIELD", 
                prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")


params <- list(commodity_desc = "CORN", util_practice_desc = "GRAIN", prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

#Download
soybeansyieldsall <- nassqs_yields(params2)

``` 

```{r, coding continued, message=FALSE}
#Tidying up the data
soybeansyieldsall$county_ansi <- as.numeric(soybeansyieldsall$county_ansi)
soybeansyieldsall$yield <- as.numeric(soybeansyieldsall$Value)

soybean_yields <- select(soybeansyieldsall, county_ansi, county_name, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
         
soybean_yields <- tibble(soybean_yields)

#A time series relationship for a given county(winneshiek)
winnsoybean <- soybean_yields %>% 
  filter(county_ansi==191)

ggplot(winnsoybean, mapping=aes(x=year, y=yield)) +
  geom_point() +
  theme_bw() +
  labs(x="Year", y="Soybeans Yield [bu/ac]", title="Soybean Yields in Winneshiek County by year") +
  geom_smooth(method = lm)

#The cross-sectional relationship for a given year(1990)
soybeans_1990 <- soybean_yields %>% 
  filter(year==1990)

ggplot(soybeans_1990, mapping=aes(x=county_ansi, y=yield), color=county_ansi) +
  geom_point() +
  theme_bw() +
  labs(x="County ANSI", y="Soybeans Yield [bu/ac]", 
       title="Soybean Yield by county across Iowa state in 1990") +
  geom_smooth(method = lm)

#Panel across all counties and years
LMFit4 <- lm(yield ~ year + as.factor(county_ansi), data=soybean_yields)
#summary(LMFit4)

soybean_yields$fitted <- LMFit4$fitted.values

ggplot(soybean_yields, mapping = aes(x=fitted, y=yield)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline (intercept = 0, slope = 1, col='red', lty='dashed') +
  theme_bw() +
  labs(x='Fitted Yield [bu/ac]', y='Actual Yield [bu/ac]',
       title='Compareing Actual and Fitted Soybean Yields in winneshiek County')

```


### Bonus: Find a package to make a county map of Iowa displaying some sort of information about yields or weather. Interpret your map.
<span style="color:blue">
**A: I used the "tidyverse" package to plot 1990 soybean yields on a map of counties in Iowa. As you can see, the southern regions of the state show low yields, while the eastern regions, such as Cedar, Clinton, and Jones counties, inferred through the "county_ansi" code, show high yields.** </span>

```{r}

us_counties <- map_data("county")

Iowa_counties <- us_counties %>% 
  filter(region=='iowa')

# head(soybeans_1990)
# head(Iowa_counties)

soybeans_1990$county_name <- tolower(soybeans_1990$county_name)

soybeans_1990_Iowa <- Iowa_counties %>% 
                      left_join(soybeans_1990, by=c("subregion"="county_name"))
# head(soybeans_1990_Iowa)

#ggplot map
ggplot(soybeans_1990_Iowa) +
  geom_polygon(mapping = aes(x=long, y=lat, group=group, fill=yield), 
               color="gray90", size=0.1) +
  scale_fill_continuous(type = 'viridis', direction=-1) +
  geom_text(aes(x=long, y=lat, label=county_ansi), 
            color="gray20", check_overlap = T, size=3) +
  theme(legend.position = 'right',
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank()) +
  ggtitle("Soybean Yields by county of IOWA state in 1990" )

```


### Bonus #2: Challenge question - map trends in corn yields by county across Iowa. Interpret your map.
<span style="color:blue">
**A: Several five-year cycle maps were obtained of corn yields by county across Iowa, as shown below. Data for some counties have been omitted, but overall, we can see a trend toward higher yields across the state over time. **

```{r}


cornyields$county_name <- tolower(cornyields$county_name)
#head(cornyields)

cornyields_Iowa <- Iowa_counties %>% 
                   left_join(cornyields, by=c("subregion"="county_name"))

ggplot(data=subset(cornyields_Iowa, year %in% c(1981, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020)),
       mapping = aes(x=long, y=lat, group=group, fill=yield)) +
       geom_polygon(color="gray90", size=0.1) +
       scale_fill_continuous(type='viridis', direction=-1 ) +
       theme(legend.position = 'right',
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank()) +
       labs(title="Corn Yields Trend in IOWA, 1981-2020", 
            fill="corn yields [bu/ac]") +
       facet_wrap(~year, ncol = 3)

```


<!--chapter:end:06-weather_corn_regression.Rmd-->

