[["index.html", "Weather and Corn Yield Regressions Chapter 1 About 1.1 How to read this book", " Weather and Corn Yield Regressions AJ Lee 3/1/2022 Chapter 1 About This is a portfolio book of the previous assignments using Bookdown package. Each bookdown chapter is an .Rmd file of the weekly assignment that I have done in ESS580A7 class so far. 1.1 How to read this book Considering the criteria below will help you understand this book more easily. Each chapter has its own topic and data. In other words, it is made up of a book, but it is complete in each chapter rather than sequentially. The content of this book is to learn various techniques such as interactive graphs, map views, and regression analysis using data, and you can discover the characteristics of each chapter. For the more convenient readability of the reader, some contents are not displayed. "],["poudre-river-overview.html", "Chapter 2 Poudre River Overview 2.1 Site 2.2 Data Acquisition and Plotting tests 2.3 Conclusions", " Chapter 2 Poudre River Overview The Poudre River is the main source of water for Fort Collins, flowing from the peaks of the Rocky Mountains into the western vast plains. The river travels through a variety of terrain, exhibiting ever-changing quantities that change with the seasons. By observing the discharge of the Poudre River, I want to understand the characteristics of the river. 2.1 Site 2.2 Data Acquisition and Plotting tests 2.2.1 Data Download I collect water discharge data upstream and downstream of Poudre by using NWIS dataset. Up &lt;- readNWISdv(siteNumbers = &#39;06752260&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2020-01-01&#39;) %&gt;% rename(Q_up = &#39;X_00060_00003&#39;) Down &lt;- readNWISdv(siteNumbers = &#39;06752280&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2020-01-01&#39;) %&gt;% rename(Q_down = &#39;X_00060_00003&#39;) River &lt;- merge (Up, Down, by=&#39;Date&#39;) 2.2.2 Interactive Data Plotter Up_xts &lt;- xts(River$Q_up, order.by = River$Date) Down_xts &lt;- xts(River$Q_down, order.by = River$Date) Discharge &lt;- cbind(Up_xts, Down_xts) dygraph(Discharge, main = &quot;Discharge of Poudre&quot;) %&gt;% dySeries(&quot;Up_xts&quot;, label = &quot;Upstream(cfs)&quot;) %&gt;% dySeries(&quot;Down_xts&quot;, label = &quot;Downstream(cfs)&quot;) %&gt;% dyLegend(show = &quot;always&quot;, hideOnMouseOut = FALSE) Figure 2.1: Discharge of the Poudre 2.3 Conclusions The Poudre River has several characteristics as below: The Poudre river tends to decrease its discharge over time. This is probably seemed due to less snow, a major water resource of the Poudre. Is it the impact of climate change? climate change impact The Flow tends to decrease as going downstream. This is believed to be due to either a runoff of water for cultivating nearby agricultural land or a sharply reduced flow rate as it approaches the plains. Do you know that the main fish that inhabits in the Poudre is Brown trout that is non-native fish? Poudre fishing report Finally, I think one of the most fun things to do in Poudre is rafting along the rough rivers in summer. If you do not yet, try it this summer. Have some cool fun in Poudre library(tidyverse) library(tidyr) library(ggthemes) library(lubridate) # Now that we have learned how to munge (manipulate) data # and plot it, we will work on using these skills in new ways knitr::opts_knit$set(root.dir=&#39;.&#39;) "],["hayman-fire-recovery.html", "Chapter 3 Hayman Fire Recovery 3.1 Question 1 3.2 Question 2 3.3 Question 3 3.4 Question 4 3.5 Question 5 3.6 Bonus Question: Redo all problems with spread and gather using modern tidyverse syntax. 3.7 Bonus Question: Use Climage Engine to pull the same data for the assignment, but updated with 2020/2021 data.", " Chapter 3 Hayman Fire Recovery ####-----Reading in Data and Stacking it ----- #### #Reading in files files &lt;- list.files(&#39;./data&#39;,full.names=T) #Read in individual data files ndmi &lt;- read.csv(files[1]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndmi&#39;) ndsi &lt;- read.csv(files[2]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndsi&#39;) ndvi &lt;- read.csv(files[3])%&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndvi&#39;) # Stack as a tidy dataset full_long &lt;- rbind(ndvi,ndmi,ndsi) %&gt;% gather(key=&#39;site&#39;,value=&#39;value&#39;,-DateTime,-data) %&gt;% filter(!is.na(value)) 3.1 Question 1 What is the correlation between NDVI and NDMI? - here I want you to convert the full_long dataset in to a wide dataset using the function spread and then make a plot that shows the correlation as a function of if the site was burned or not (x axis should be ndmi) You should exclude winter months and focus on summer months. A: NDVI and NDMI are positively correlated. This is easy to understand given that moisture is an important element of vegetation. In particular, the unburned area showed a clearer relationship within the narrow vegetation range than the burned area. The burned area shows a broad plot due to the fire, but still appears to be closely related to moisture. full_wide &lt;- spread(data=full_long, key=&#39;data&#39;, value=&#39;value&#39;) %&gt;% filter_if(is.numeric, all_vars(!is.na(.))) %&gt;% mutate(month = month(DateTime), year = year(DateTime)) summer_only &lt;- filter(full_wide, month %in% c(6,7,8,9)) ggplot(summer_only,aes(x=ndmi, y=ndvi, color=site)) + geom_point() + theme_few() + scale_color_few() + theme(legend.position=c(0.8,0.8)) Figure 3.1: Correlation between NDVI and NDMI 3.2 Question 2 What is the correlation between average NDSI (normalized snow index) for January - April and average NDVI for June-August? In other words, does the previous years snow cover influence vegetation growth for the following summer? A: NDVI and NDSI do not appear to show a significant correlation in this study. As shown in the graph, snow cover does not seem to have a significant effect on vegetation growth because ndvi maintains a constant value regardless of increase in ndsi. However, a different pattern can be seen for burned areas. Although it is not certain, it is judged that snow is helpful for the growth of plants in burnt areas remained devastated, because it shows a slight positive correlation between ndsi and ndvi. NDSI_NDVI &lt;- mutate(full_long, month=month(DateTime), year=year(DateTime)) %&gt;% filter((data==&#39;ndsi&#39; &amp; month %in% c(1:4))|(data==&#39;ndvi&#39; &amp; month %in% c(6,7,8))) %&gt;% group_by(data,site,year) %&gt;% summarize(mean_value=mean(value)) %&gt;% spread(key=&#39;data&#39;, value=&#39;mean_value&#39;) ggplot(NDSI_NDVI, aes(x=ndsi, y=ndvi, color=year)) + geom_point() + theme_few() + theme(legend.position=c(0.8,0.2)) + facet_wrap(~site) Figure 3.2: Correlation between average NDSI, NDVI 3.3 Question 3 How is the snow effect from question 2 different between pre- and post-burn and burned and unburned? A: As can be seen in the graph above, the vegetation index decreased sharply after the fire, but considering that the correlation between NDSI and NDVI in the wildfire area showed a slight positive correlation in the wide range, the snow impact for growth of plant appears to be greater than before. In un-burned areas, plant growth seems to be constant regardless of the amount of snow. And if you look at the color of the plots, you can see that it is trending less snow these days than it was in the past. 3.4 Question 4 What month is the greenest month on average? Does this change in the burned plots after the fire? A: Before the wildfire, September was the greenest month on average, and after the fire, August was the greenest month in burned area. The cause of the difference is unclear, but it is speculated that the greenest month has changed as forest fires have removed trees that could have remained green until September. Green_ndvi &lt;- gather(ndvi, key=&#39;site&#39;,value=&#39;NDVI&#39;,-DateTime,-data) %&gt;% filter(!is.na(NDVI)) %&gt;% mutate(month = month(DateTime)) %&gt;% group_by(site, month) %&gt;% summarize(mean_NDVI=mean(NDVI)) ggplot(Green_ndvi, aes(x=month, y=mean_NDVI, color=site)) + geom_point() + geom_line(linetype=2) + theme_few() + scale_color_few() + theme(legend.position=c(0.5,0.2)) + annotate(&quot;rect&quot;, xmin=8, xmax = 9, ymin = 0.1, ymax=0.46, alpha=.1, fill=&#39;blue&#39;) Figure 3.3: The greenest month on average after fire 3.5 Question 5 What month is the snowiest on average? A: Before the wildfire, February was the snowiest month on average, and after the fire, January was ranked the snowiest month on average in burned area. The cause of this difference is also unclear as in Question 4, but it is presumed that the density of vegetation influenced the amount of snow cover. Snow_ndsi &lt;- gather(ndsi, key=&#39;site&#39;, value=&#39;NDSI&#39;, -DateTime, -data) %&gt;% filter(!is.na(NDSI)) %&gt;% mutate(month = month(DateTime)) %&gt;% group_by(site, month) %&gt;% summarize(mean_NDSI=mean(NDSI)) ggplot(Snow_ndsi, aes(x=month, y=mean_NDSI, color=site)) + geom_point() + geom_line(linetype=2) + theme_few() + scale_color_few() + theme(legend.position=c(0.5,0.8)) Figure 3.4: The snowiest month on average after fire 3.6 Bonus Question: Redo all problems with spread and gather using modern tidyverse syntax. 3.7 Bonus Question: Use Climage Engine to pull the same data for the assignment, but updated with 2020/2021 data. "],["snow-function-iteration.html", "Chapter 4 Snow function iteration 4.1 Simple web scraping 4.2 Q1. Reading an html 4.3 Q2. Data Download 4.4 Q3. Read pdf to make a new column header appending a site column 4.5 Q4. Read the forcing data using map function and summary 4.6 Q5. Plot mean temperature data 4.7 Q6. Plot monthly average temperature 4.8 Bonus1, Daily precipitation by year 4.9 Bonus2, yearly plots of percipitation by day of year", " Chapter 4 Snow function iteration 4.1 Simple web scraping R can read html using either rvest, xml, or xml2 packages. Here we are going to navigate to the Center for Snow and Avalance Studies Website and read a table in. This table contains links to data we want to programatically download for three sites. We dont know much about these sites, but they contain incredibly rich snow, temperature, and precip data. 4.2 Q1. Reading an html 4.2.1 Extract txt links from webpage site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; #Read the web url webpage &lt;- read_html(site_url) #See if we can extract tables and get the data that way tables &lt;- webpage %&gt;% html_nodes(&#39;table&#39;) %&gt;% magrittr::extract2(3) %&gt;% html_table(fill = TRUE) #That didn&#39;t work, so let&#39;s try a different approach #Extract only weblinks and then the URLs! links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 4.3 Q2. Data Download 4.3.1 Download data in a for loop #Grab only the name of the file by splitting out on forward slashes splits &lt;- str_split_fixed(links,&#39;/&#39;,8) #Keep only the 7th column dataset &lt;- splits[,8] #generate a file list for where the data goes file_names &lt;- paste0(&#39;data/&#39;, dataset) for(i in 1:2){ download.file(links[i],destfile=file_names[i]) } downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(downloaded) 4.3.2 Download data in a map #Map version of the same for loop (downloading 3 files) if(evaluate == T){ map2(links[1:2],file_names[1:2],download.file) }else{print(&#39;data already downloaded&#39;)} ## [1] &quot;data already downloaded&quot; 4.4 Q3. Read pdf to make a new column header appending a site column #Grabs the variable names from the metadata pdf file library(pdftools) headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) %&gt;% append(&quot;site&quot;) 4.5 Q4. Read the forcing data using map function and summary #Read the data as a map function our_forcing_reader &lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2] %&gt;% gsub(&#39;_Forcing_Data.txt&#39;,&#39;&#39;,.) %&gt;% gsub(&#39;SBB_&#39;,&#39;&#39;,.) df &lt;- read.delim(file, header = F, sep = &quot;&quot;, col.names = headers) %&gt;% select(year, month, air.temp..K., site) %&gt;% mutate(site = name) } forcing_data_full &lt;- map_dfr(file_names, our_forcing_reader) summary(forcing_data_full) ## year month air.temp..K. site ## Min. :2003 Min. : 1.000 Min. :242.1 Length:138336 ## 1st Qu.:2005 1st Qu.: 3.000 1st Qu.:265.8 Class :character ## Median :2007 Median : 6.000 Median :272.6 Mode :character ## Mean :2007 Mean : 6.472 Mean :272.6 ## 3rd Qu.:2009 3rd Qu.: 9.000 3rd Qu.:279.7 ## Max. :2011 Max. :12.000 Max. :295.8 4.6 Q5. Plot mean temperature data A: The mean temperature in SASP is always warmer than the one of SBSP. #make annually mean temperature data frame temp_yearly &lt;- forcing_data_full %&gt;% group_by(year, site) %&gt;% summarize(mean_temp = mean(air.temp..K.,na.rm=T)) #plot graph ggplot(temp_yearly,aes(x=year,y=mean_temp,color=site)) + geom_point() + geom_line() + labs(x=&#39;Year&#39;, y=&#39;Mean temperature (Kelvin)&#39;) + ggthemes::theme_few() + ggthemes::scale_color_few() + theme(legend.position=c(0.8,0.3)) Figure 4.1: The mean temperature 4.7 Q6. Plot monthly average temperature A: As can be seen graphs below, the monthly average temperature at the SASP(Snow Angel Study Plot) is always higher than the one of SBSP(Senator Beck Study Plot) in any given years from 2005 to 2010. So, we cant say that SBSP is warmer than SASP #make monthly temperature data frame temp_monthly &lt;- forcing_data_full %&gt;% group_by(year, month, site) %&gt;% summarize(average_temp = mean(air.temp..K.,na.rm=T)) #plot the graph by given year(2005~2010) for(i in 2005:2010){ temp_monthly_by_year &lt;- filter(temp_monthly, year==i) plot(ggplot(temp_monthly_by_year, aes(x=month, y=average_temp, color = site)) + geom_point() + geom_line() + ggthemes::theme_few() + ggthemes::scale_color_few() + theme(legend.position=c(0.1,0.8)) + labs(title=i, y=&quot;Monthly Mean Temperature (K)&quot;, x=&quot;Month&quot;)) } Figure 4.2: Monthly average temperature by year 4.8 Bonus1, Daily precipitation by year #Read the data as a map function &amp; append a site column to the data our_precip_reader &lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2] %&gt;% gsub(&#39;_Forcing_Data.txt&#39;,&#39;&#39;,.) %&gt;% gsub(&#39;SBB_&#39;,&#39;&#39;,.) df &lt;- read.delim(file, header = F, sep = &quot;&quot;, col.names = headers) %&gt;% select(year, month, day, precip..kg.m.2.s.1.) %&gt;% mutate(site = name) } precip_data_full &lt;- map_dfr(file_names, our_precip_reader) #average daily precipitation by year precip_yearly &lt;- precip_data_full %&gt;% group_by(year, month, day, site) %&gt;% summarize(daily_precip = mean(precip..kg.m.2.s.1.,na.rm=T)*24*3600) ggplot(precip_yearly,aes(x=year,y=daily_precip, color=site)) + geom_point() + geom_line() + labs(x=&quot;Year&quot;, y=&quot;Daily Precipitation (mm)&quot;) + ggthemes::theme_few() + ggthemes::scale_color_few() + theme(legend.position=c(0.8,0.8)) Figure 4.3: Daily precipitation by year 4.9 Bonus2, yearly plots of percipitation by day of year precip_daily &lt;- precip_data_full %&gt;% group_by(year, month, site) %&gt;% summarize(average_day_precip = mean(precip..kg.m.2.s.1.,na.rm=T)*24*3600) #plot the graph by given year(2005~2010) par(mfrow=c(2,3)) for(i in 2005:2010){ precip_daily_by_year &lt;- filter(precip_daily, year==i) plot(x=precip_daily_by_year$month, y=precip_daily_by_year$average_day_precip, xlab=&quot;month&quot;, ylab=&quot;average daily precipitation (mm)&quot;, main = i, type=&quot;b&quot;) } Figure 4.4: Yearly plots of Daily precipitation by year "],["lagos-analysis.html", "Chapter 5 LAGOS Analysis 5.1 Loading in data 5.2 In-Class work", " Chapter 5 LAGOS Analysis 5.1 Loading in data 5.1.1 First download and then specifically grab the locus (or site lat longs) # #Lagos download script LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path()) #Load in lagos lagos &lt;- lagosne_load() #Grab the lake centroid info lake_centers &lt;- lagos$locus 5.1.2 Convert to spatial data #Look at the column names #names(lake_centers) #Look at the structure #str(lake_centers) #View the full dataset #View(lake_centers %&gt;% slice(1:100)) spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) #Subset for plotting subset_spatial &lt;- spatial_lakes %&gt;% slice(1:100) subset_baser &lt;- spatial_lakes[1:100,] #Dynamic mapviewer #mapview(subset_spatial) 5.1.3 Subset to only Minnesota states &lt;- us_states() #Plot all the states to check if they loaded #mapview(states) minnesota &lt;- states %&gt;% filter(name == &#39;Minnesota&#39;) %&gt;% st_transform(2163) #Subset lakes based on spatial position minnesota_lakes &lt;- spatial_lakes[minnesota,] #Plotting the first 1000 lakes minnesota_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;) 5.2 In-Class work 5.2.1 1) Show a map outline of Iowa and Illinois (similar to Minnesota map upstream) Iowa_Illinois &lt;- states %&gt;% filter(name %in% c(&#39;Iowa&#39;, &#39;Illinois&#39;)) %&gt;% st_transform(2163) mapview(Iowa_Illinois) 5.2.2 2) Subset LAGOS data to these sites, how many sites are in Illinois and Iowa combined? How does this compare to Minnesota? A: Iowa and Illinois have 16,466 sites, fewer than Minnesota, which has 29,038. Iowa_Illinois_lakes &lt;- spatial_lakes[Iowa_Illinois,] nrow(Iowa_Illinois_lakes) ## [1] 16466 nrow(minnesota_lakes) ## [1] 29038 5.2.3 3) What is the distribution of lake size in Iowa vs. Minnesota? Here I want to see a histogram plot with lake size on x-axis and frequency on y axis (check out geom_histogram) A: As can be seen in the histogram below, both Iowa and Minnesota show a larger distribution of numbers with smaller lakes. However, since the number of lakes in Minnesota is much higher than in Iowa, it can be seen that the distribution of lakes is more diverse and wider. # Make Iowa&#39;s lake size data not Iowa_Illinois, using lake area Iowa &lt;- states %&gt;% filter(name==&#39;Iowa&#39;) %&gt;% st_transform(2163) Iowa_lakes &lt;- spatial_lakes[Iowa,] Iowa_lakes_size &lt;- data.frame(Iowa_lakes$lake_area_ha) %&gt;% rename(Lake_Size=1) %&gt;% mutate(State=&#39;Iowa&#39;) # Make Minnesota&#39;s lakes size data in similar way minnesota_lakes_size &lt;- data.frame(minnesota_lakes$lake_area_ha) %&gt;% rename(Lake_Size=1) %&gt;% mutate(State=&#39;Minnesota&#39;) # Bind two data frames to make a plot Compare_lake_size &lt;- rbind(Iowa_lakes_size, minnesota_lakes_size) # Make a histogram plot p&lt;- ggplot(Compare_lake_size, aes(x=Lake_Size, fill=State)) + xlim(1,200) + xlab(&#39;Lake Size(ha)&#39;) + geom_histogram(bins = 100, alpha=0.5) + theme_few() + theme(legend.position=c(0.8,0.7)) p+scale_fill_manual(values = c(&quot;Red&quot;, &quot;Green&quot;)) Figure 5.1: Compare lake size between Iowa and Minnesota 5.2.4 4) Make an interactive plot of lakes in Iowa and Illinois and color them by lake area in hectares Iowa_Illinois_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;) 5.2.5 5) What other data sources might we use to understand how reservoirs and natural lakes vary in size in these three states? A: For comparing lake size in another way, you can use perimeter length of lakes instead of lake area. The map below shows the variation of lake size using perimeter of lakes in three states. Compare_lake_length &lt;- rbind(minnesota_lakes, Iowa_Illinois_lakes) Compare_lake_length %&gt;% arrange(-lake_perim_meters) %&gt;% slice(1:1000) %&gt;% mapview(., zcol=&#39;lake_perim_meters&#39;) "],["lagos-analysis-2.html", "Chapter 6 LAGOS Analysis 2 6.1 Loading in data 6.2 Class work", " Chapter 6 LAGOS Analysis 2 6.1 Loading in data 6.1.1 First download and then specifically grab the locus (or site lat longs) #Lagos download script # lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T) #Load in lagos lagos &lt;- lagosne_load() #Grab the lake centroid info lake_centers &lt;- lagos$locus # Make an sf object spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) #Grab the water quality data nutr &lt;- lagos$epi_nutr #Look at column names #names(nutr) 6.1.2 Subset columns nutr to only keep key info that we want clarity_only &lt;- nutr %&gt;% select(lagoslakeid,sampledate,chla,doc,secchi) %&gt;% mutate(sampledate = as.character(sampledate) %&gt;% ymd(.)) 6.1.3 Keep sites with at least 200 observations #Look at the number of rows of dataset #nrow(clarity_only) chla_secchi &lt;- clarity_only %&gt;% filter(!is.na(chla), !is.na(secchi)) # How many observatiosn did we lose? # nrow(clarity_only) - nrow(chla_secchi) # Keep only the lakes with at least 200 observations of secchi and chla chla_secchi_200 &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% filter(count &gt; 200) 6.1.4 Join water quality data to spatial data spatial_200 &lt;- inner_join(spatial_lakes,chla_secchi_200 %&gt;% distinct(lagoslakeid,.keep_all=T), by=&#39;lagoslakeid&#39;) # mapview(spatial_200) 6.1.5 Mean Chl_a map ### Take the mean chl_a and secchi by lake mean_values_200 &lt;- chla_secchi_200 %&gt;% # Take summary by lake id group_by(lagoslakeid) %&gt;% # take mean chl_a per lake id summarize(mean_chl = mean(chla,na.rm=T), mean_secchi=mean(secchi,na.rm=T)) %&gt;% #Get rid of NAs filter(!is.na(mean_chl), !is.na(mean_secchi)) %&gt;% # Take the log base 10 of the mean_chl mutate(log10_mean_chl = log10(mean_chl)) #Join datasets mean_spatial &lt;- inner_join(spatial_lakes,mean_values_200, by=&#39;lagoslakeid&#39;) #Make a map mapview(mean_spatial,zcol=&#39;log10_mean_chl&#39;) 6.2 Class work 6.2.1 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for sites with at least 200 observations? Here, I just want a plot of chl vs secchi for all sites A: The plot below shows that high chlorophyll(chla) shorten the depth of secchi disk, which means a negative correlation. #Your code here plot(mean_chl ~ mean_secchi, data=mean_spatial, xlab=&quot;Mean secchi (m)&quot; , ylab=&quot;Mean Chlorophyll (mg/L)&quot;) 6.2.2 Why might this be the case? A: The increase in chlorophyll in the water means high turbidity, and it is difficult to see the secchi disk to the depths because it interferes with visibility in the water. 6.2.3 2) What states have the most data? 6.2.3.1 2a) First you will need to make a lagos spatial dataset that has the total number of counts per site. #head(chla_secchi) chla_secchi_most &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% summarize(Total_by_lake = sum(count)) spatial_most &lt;- inner_join(spatial_lakes,chla_secchi_most, by=&#39;lagoslakeid&#39;) 6.2.3.2 2b) Second, you will need to join this point dataset to the us_boundaries data. states &lt;- us_states() %&gt;% st_transform(2163) US_spatial_most &lt;- st_join(spatial_most, states) # mapview(US_spatial_most) 6.2.3.3 2c) Then you will want to group by state and sum all the observations in that state and arrange that data from most to least total observations per state. A: The state has the most data about lake is Minnesota, which observation number is about over 6 million in chlorophyll and secchi data record. US_lake_Observation &lt;- US_spatial_most %&gt;% group_by(name) %&gt;% summarize(Observation=sum(Total_by_lake)) %&gt;% arrange(-Observation) # head(US_lake_Observation) mapview(US_lake_Observation, zcol=&#39;Observation&#39;) 6.2.3.4 Bonus: Map of total observation number by state not lake sites spatial_most_state &lt;- inner_join(spatial_most, lagos$state, by=&#39;state_zoneid&#39;) %&gt;% select(&#39;state_name&#39;, &#39;Total_by_lake&#39;) %&gt;% group_by(state_name) %&gt;% summarize(Observation=sum(Total_by_lake)) spatial_most_state$geometry &lt;- NULL US_lake_Observation_option &lt;- inner_join(states, spatial_most_state, by=&#39;state_name&#39;) mapview(US_lake_Observation_option, zcol=&#39;Observation&#39;) 6.2.4 3) Is there a spatial pattern in Secchi disk depth for lakes with at least 200 observations? A: It can be seen that the high secchi depth value, which means the clarity of water, is mainly distributed in the northeastern regions such as Minnesota, Michigan, New York, and Maine. # Extract the secchi data from original nutrition data Secchi &lt;- nutr %&gt;% select(lagoslakeid, sampledate, secchi) %&gt;% mutate(sampledate = as.character(sampledate) %&gt;% ymd(.)) # Filter only the data above 200 observation Secchi_200 &lt;- Secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count=n()) %&gt;% filter(count &gt; 200) # Join the data to spatial platform Secchi_200_spatial &lt;- inner_join(spatial_lakes, Secchi_200, by=&#39;lagoslakeid&#39;) %&gt;% arrange(-secchi) %&gt;% slice(1:30000) # Check a spatial pattern using mapview mapview(Secchi_200_spatial, zcol=&#39;secchi&#39;) "],["weather-data-analysis.html", "Chapter 7 Weather Data Analysis 7.1 Load the PRISM daily maximum temperatures 7.2 Temperature trends", " Chapter 7 Weather Data Analysis 7.1 Load the PRISM daily maximum temperatures 7.2 Temperature trends 7.2.1 Summer temperature trends: Winneshiek County 7.2.2 Winter Temperatures - Winneshiek County 7.2.3 Multiple regression  Quadratic time trend 7.2.4 Download NASS corn yield data ## Assignment 7.2.5 Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend? A: As seen the graph below, we can say the trend of corn yield in Winneshiek County has been increasing over time. winncorn &lt;- cornyields %&gt;% filter(county_ansi == 191) ggplot(winncorn, mapping = aes(x= year, y= yield)) + geom_point() + theme_bw() + labs(x=&#39;Year&#39;, y=&#39;Corn yield [bu/ac]&#39;) + geom_smooth(method = lm , color=&#39;red&#39;) 7.2.6 Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? A: The plot line (blue) with quadratic time trend applied is seemed to have no evidence for slowing yield growth. Instead it shows a similar trend to the previous actual yield graph because the regression plot line is same with reference line(red). winncorn$yearsq &lt;- (winncorn$year)^2 lm_winncornquad &lt;- lm(yield ~ year + yearsq, winncorn) summary(lm_winncornquad) ## ## Call: ## lm(formula = yield ~ year + yearsq, data = winncorn) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.384 -3.115 1.388 9.743 25.324 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.583e+04 8.580e+04 0.301 0.765 ## year -2.812e+01 8.576e+01 -0.328 0.745 ## yearsq 7.641e-03 2.143e-02 0.357 0.723 ## ## Residual standard error: 17.17 on 38 degrees of freedom ## Multiple R-squared: 0.7559, Adjusted R-squared: 0.7431 ## F-statistic: 58.84 on 2 and 38 DF, p-value: 2.311e-12 winncorn$fitted &lt;- lm_winncornquad$fitted.values ggplot(winncorn, mapping = aes(x = fitted, y = yield)) + geom_point() + geom_smooth(method=lm) + geom_abline(intercept = 0, slope = 1, color=&#39;red&#39;, lty=&#39;dashed&#39;) + theme_bw() + labs(x = &quot;Fitted Yield&quot;, y = &quot;Actual Yield&quot;) 7.2.7 Question 2  Time Series: Lets analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results. A: The relationship between temperature and yield in the winneshiek time series shows a generally negative trend as shown in the figures below. In particular, linear regression models with Tmax squared as a predictor give a very distinct quadratic equation result. So we will be able to predict accurate corn yields using this model. winncorn_tmax &lt;- inner_join(winncorn, winnesummer, by= &#39;year&#39;) %&gt;% select(county_name, year, yield, meantmax) # str(winncorn_tmax) #1) Corn yield ~ Tmax lm_winncorn_tmax &lt;- lm(yield ~ meantmax, winncorn_tmax) summary(lm_winncorn_tmax) ## ## Call: ## lm(formula = yield ~ meantmax, data = winncorn_tmax) ## ## Residuals: ## Min 1Q Median 3Q Max ## -71.96 -19.85 -3.19 24.64 61.72 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 275.876 118.335 2.331 0.0255 * ## meantmax -4.763 4.438 -1.073 0.2902 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 32.88 on 36 degrees of freedom ## Multiple R-squared: 0.03101, Adjusted R-squared: 0.004098 ## F-statistic: 1.152 on 1 and 36 DF, p-value: 0.2902 ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=yield, color=year)) + geom_point() + theme_bw() + labs(x=&#39;Tmax (°C)&#39;, y=&#39;Corn yield [bu/ac]&#39;) + ggtitle(&quot;Relation between Corn yield and Summer Temperature&quot;) + geom_smooth(method=lm) #2) Add year prediction variable lm_winncorn_tmax_year &lt;- lm(yield ~ meantmax + year, winncorn_tmax) summary(lm_winncorn_tmax_year) ## ## Call: ## lm(formula = yield ~ meantmax + year, data = winncorn_tmax) ## ## Residuals: ## Min 1Q Median 3Q Max ## -53.071 -7.269 2.271 9.935 27.505 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4791.774 513.812 -9.326 5.10e-11 *** ## meantmax -3.201 2.308 -1.387 0.174 ## year 2.514 0.253 9.934 1.01e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.06 on 35 degrees of freedom ## Multiple R-squared: 0.7463, Adjusted R-squared: 0.7318 ## F-statistic: 51.48 on 2 and 35 DF, p-value: 3.761e-11 winncorn_tmax$fitted_year &lt;- lm_winncorn_tmax_year$fitted.values ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=fitted_year, color=year)) + geom_point() + theme_bw() + labs(x=&#39;Tmax (°C)&#39;, y=&#39;Corn yield [bu/ac]&#39;) + ggtitle(&quot;Relation between Corn yield and Summer Temperature&quot;) + geom_smooth(method=lm) #3) OR Add Tmax squared prediction variable winncorn_tmax$tmaxsq &lt;- (winncorn_tmax$meantmax)^2 lm_winncorn_tmaxsq &lt;- lm(yield ~ meantmax + tmaxsq, winncorn_tmax) summary(lm_winncorn_tmaxsq) ## ## Call: ## lm(formula = yield ~ meantmax + tmaxsq, data = winncorn_tmax) ## ## Residuals: ## Min 1Q Median 3Q Max ## -56.587 -22.262 -0.982 22.409 52.798 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4223.604 1446.639 -2.920 0.00609 ** ## meantmax 328.918 107.068 3.072 0.00410 ** ## tmaxsq -6.173 1.979 -3.119 0.00362 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.5 on 35 degrees of freedom ## Multiple R-squared: 0.2417, Adjusted R-squared: 0.1984 ## F-statistic: 5.579 on 2 and 35 DF, p-value: 0.007887 winncorn_tmax$fitted_tmaxsq &lt;- lm_winncorn_tmaxsq$fitted.values ggplot(winncorn_tmax, mapping = aes(x=meantmax, y=fitted_tmaxsq, color=year)) + geom_point() + theme_bw() + labs(x=&#39;Tmax (°C)&#39;, y=&#39;Corn yield [bu/ac]&#39;) + ggtitle(&quot;Relation between Corn yield and Summer Temperature&quot;) + geom_smooth(method=loess) 7.2.8 Question 3  Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results. A: Based on the result of regression analysis, the p-value is less than alpha(=0.05), so we can determine that there is a relationship between temperature and yield, and the relationship is positive trend as you can see the below figure. #Extract temperature data across all counties in 1981 tmaxdf_1981 &lt;- tmaxdf %&gt;% filter(year==1981 &amp; day &gt;= 152 &amp; day &lt;=243 &amp; !is.na(tmax)) %&gt;% group_by(countyfp) %&gt;% summarise(meantmax = mean(tmax)) tmaxdf_1981$countyfp &lt;- as.numeric(tmaxdf_1981$countyfp) #Extract yield data across all counties in 1981, and Change column name to join two dataset cornyields_1981 &lt;- cornyields %&gt;% filter(year==1981, !is.na(yield)) colnames(cornyields_1981)[1] &lt;- &quot;countyfp&quot; #Join two dataset Tmax_yield_all &lt;- inner_join(tmaxdf_1981, cornyields_1981, by=&quot;countyfp&quot;) ggplot(Tmax_yield_all, mapping = aes(x=meantmax, y=yield)) + geom_point() + theme_bw() + labs(x=&#39;Tmax (°C)&#39;, y=&#39;Corn yield [bu/ac]&#39;, title=&#39;Relation between temperature and yield in 2018&#39;)+ geom_smooth(method=lm) #Analyze regression LMFit &lt;- lm(yield ~ meantmax, data=Tmax_yield_all) summary(LMFit) ## ## Call: ## lm(formula = yield ~ meantmax, data = Tmax_yield_all) ## ## Residuals: ## Min 1Q Median 3Q Max ## -31.4448 -4.8675 0.7887 6.1170 21.5695 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.670 53.799 0.124 0.9018 ## meantmax 4.348 1.955 2.224 0.0309 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.83 on 48 degrees of freedom ## Multiple R-squared: 0.09341, Adjusted R-squared: 0.07452 ## F-statistic: 4.946 on 1 and 48 DF, p-value: 0.0309 7.2.9 Question 4  Panel: One way to leverage multiple time series is to group all data into what is called a panel regression. Convert the county ID code (countyfp or county_ansi) into factor using as.factor, then include this variable in a regression using all counties yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model. A: The result of comparing actual and fitted yields is almost same to reference line(red, y=x). So to say, we would probably able to infer predicted corn yield close to actual yields through this panel regression model. And there is no significant difference in the result due to temperature coefficients change(Tmax, Tmaxsq). #Extract temperature data across all counties tmaxdf_years &lt;- tmaxdf %&gt;% filter(day &gt;= 152 &amp; day &lt;=243 &amp; !is.na(tmax)) %&gt;% group_by(countyfp) %&gt;% summarise(meantmax = mean(tmax)) #Extract yield data across all counties, and Change column name to join two dataset cornyields_years &lt;- cornyields %&gt;% filter(!is.na(yield)) colnames(cornyields_years)[1] &lt;- &quot;countyfp&quot; cornyields_years$countyfp &lt;- as.factor(cornyields_years$countyfp) #Join two dataset Tmax_yield_all_years &lt;- inner_join(tmaxdf_years, cornyields_years, by=&quot;countyfp&quot;) #Regression analysis and plot -Tmax LMFit2 &lt;- lm(yield ~ meantmax + countyfp, data=Tmax_yield_all_years) #summary(LMFit2) Tmax_yield_all_years$fitted &lt;- LMFit2$fitted.values ggplot(Tmax_yield_all_years, mapping = aes(x=fitted, y=yield)) + geom_point() + geom_smooth (method = lm) + geom_abline(intercept = 0, slope = 1, color=&#39;red&#39;, lty=&#39;dashed&#39;) + theme_bw() + labs(x=&#39;Fitted Yield&#39;, y=&#39;Actual Yield&#39;, title=&#39;Compareing Actual and Fitted Yields in panel regression (Tmax)&#39;) #Regression analysis and plot -Tmax squared Tmax_yield_all_years$tmaxsq &lt;- (Tmax_yield_all_years$meantmax)^2 LMFit3 &lt;- lm(yield ~ meantmax + tmaxsq + countyfp , data=Tmax_yield_all_years) #summary(LMFit3) Tmax_yield_all_years$fitted2 &lt;- LMFit3$fitted.values ggplot(Tmax_yield_all_years, mapping = aes(x=fitted2, y=yield)) + geom_point() + geom_smooth(method = lm) + geom_abline (intercept = 0, slope = 1, col=&#39;red&#39;, lty=&#39;dashed&#39;) + theme_bw() + labs(x=&#39;Fitted Yield&#39;, y=&#39;Actual Yield&#39;, title=&#39;Compareing Actual and Fitted Yields in panel regression (Tmax+Tmaxsq)&#39;) 7.2.10 Question 5  Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years. A: We can find the correlation under various conditions through the below figures. #Parameters to query on for soybean data params2 &lt;- list(commodity_desc = &quot;SOYBEANs&quot;, statisticcat_desc=&quot;YIELD&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1981, state_alpha = &quot;IA&quot;) params &lt;- list(commodity_desc = &quot;CORN&quot;, util_practice_desc = &quot;GRAIN&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1981, state_alpha = &quot;IA&quot;) #Download soybeansyieldsall &lt;- nassqs_yields(params2) #Tidying up the data soybeansyieldsall$county_ansi &lt;- as.numeric(soybeansyieldsall$county_ansi) soybeansyieldsall$yield &lt;- as.numeric(soybeansyieldsall$Value) soybean_yields &lt;- select(soybeansyieldsall, county_ansi, county_name, yield, year) %&gt;% filter(!is.na(county_ansi) &amp; !is.na(yield)) soybean_yields &lt;- tibble(soybean_yields) #A time series relationship for a given county(winneshiek) winnsoybean &lt;- soybean_yields %&gt;% filter(county_ansi==191) ggplot(winnsoybean, mapping=aes(x=year, y=yield)) + geom_point() + theme_bw() + labs(x=&quot;Year&quot;, y=&quot;Soybeans Yield [bu/ac]&quot;, title=&quot;Soybean Yields in Winneshiek County by year&quot;) + geom_smooth(method = lm) #The cross-sectional relationship for a given year(1990) soybeans_1990 &lt;- soybean_yields %&gt;% filter(year==1990) ggplot(soybeans_1990, mapping=aes(x=county_ansi, y=yield), color=county_ansi) + geom_point() + theme_bw() + labs(x=&quot;County ANSI&quot;, y=&quot;Soybeans Yield [bu/ac]&quot;, title=&quot;Soybean Yield by county across Iowa state in 1990&quot;) + geom_smooth(method = lm) #Panel across all counties and years LMFit4 &lt;- lm(yield ~ year + as.factor(county_ansi), data=soybean_yields) #summary(LMFit4) soybean_yields$fitted &lt;- LMFit4$fitted.values ggplot(soybean_yields, mapping = aes(x=fitted, y=yield)) + geom_point() + geom_smooth(method = lm) + geom_abline (intercept = 0, slope = 1, col=&#39;red&#39;, lty=&#39;dashed&#39;) + theme_bw() + labs(x=&#39;Fitted Yield [bu/ac]&#39;, y=&#39;Actual Yield [bu/ac]&#39;, title=&#39;Compareing Actual and Fitted Soybean Yields in winneshiek County&#39;) 7.2.11 Bonus: Find a package to make a county map of Iowa displaying some sort of information about yields or weather. Interpret your map. A: I used the tidyverse package to plot 1990 soybean yields on a map of counties in Iowa. As you can see, the southern regions of the state show low yields, while the eastern regions, such as Cedar, Clinton, and Jones counties, inferred through the county_ansi code, show high yields. us_counties &lt;- map_data(&quot;county&quot;) Iowa_counties &lt;- us_counties %&gt;% filter(region==&#39;iowa&#39;) # head(soybeans_1990) # head(Iowa_counties) soybeans_1990$county_name &lt;- tolower(soybeans_1990$county_name) soybeans_1990_Iowa &lt;- Iowa_counties %&gt;% left_join(soybeans_1990, by=c(&quot;subregion&quot;=&quot;county_name&quot;)) # head(soybeans_1990_Iowa) #ggplot map ggplot(soybeans_1990_Iowa) + geom_polygon(mapping = aes(x=long, y=lat, group=group, fill=yield), color=&quot;gray90&quot;, size=0.1) + scale_fill_continuous(type = &#39;viridis&#39;, direction=-1) + geom_text(aes(x=long, y=lat, label=county_ansi), color=&quot;gray20&quot;, check_overlap = T, size=3) + theme(legend.position = &#39;right&#39;, axis.line = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), panel.background = element_blank(), panel.border = element_blank(), panel.grid = element_blank()) + ggtitle(&quot;Soybean Yields by county of IOWA state in 1990&quot; ) ## Warning: Removed 5 rows containing missing values (geom_text). 7.2.12 Bonus #2: Challenge question - map trends in corn yields by county across Iowa. Interpret your map. A: Several five-year cycle maps were obtained of corn yields by county across Iowa, as shown below. Data for some counties have been omitted, but overall, we can see a trend toward higher yields across the state over time. cornyields$county_name &lt;- tolower(cornyields$county_name) #head(cornyields) cornyields_Iowa &lt;- Iowa_counties %&gt;% left_join(cornyields, by=c(&quot;subregion&quot;=&quot;county_name&quot;)) ggplot(data=subset(cornyields_Iowa, year %in% c(1981, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020)), mapping = aes(x=long, y=lat, group=group, fill=yield)) + geom_polygon(color=&quot;gray90&quot;, size=0.1) + scale_fill_continuous(type=&#39;viridis&#39;, direction=-1 ) + theme(legend.position = &#39;right&#39;, axis.line = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), panel.background = element_blank(), panel.border = element_blank(), panel.grid = element_blank()) + labs(title=&quot;Corn Yields Trend in IOWA, 1981-2020&quot;, fill=&quot;corn yields [bu/ac]&quot;) + facet_wrap(~year, ncol = 3) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
